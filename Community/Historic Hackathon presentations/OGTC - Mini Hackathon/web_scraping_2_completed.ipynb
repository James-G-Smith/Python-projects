{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Copy of Copy of Copy of Copy of Untitled0.ipynb","version":"0.3.2","provenance":[{"file_id":"1GuhbUNpN8MQtF_ZXVcZu4G6Q7cxTNjB_","timestamp":1552422287611},{"file_id":"1FcMwiG0M7lVM_ZA-CJm09dRkUAbkvh-v","timestamp":1552421872090},{"file_id":"https://github.com/James-G-Smith/Python-projects/blob/master/OGTC%20-%20Mini%20Hackathon/web_scraping_2.ipynb","timestamp":1552421816112},{"file_id":"1bAsVr-XSd4qmhX_Qg3By42AtpdgaCy-j","timestamp":1552042464428},{"file_id":"1esc0gAFzsCb160JykYlj77J0cDjFpWq_","timestamp":1552042027732}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"R6KTfyNq49sO","colab_type":"code","outputId":"2771df31-9608-4f0b-e6e7-b203204a71e8","executionInfo":{"status":"ok","timestamp":1552422131079,"user_tz":0,"elapsed":52109,"user":{"displayName":"James Smith","photoUrl":"https://lh6.googleusercontent.com/-Zw644239oys/AAAAAAAAAAI/AAAAAAAAHQ8/X--mkDYPOtc/s64/photo.jpg","userId":"09476109974115373126"}},"colab":{"base_uri":"https://localhost:8080/","height":438}},"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","\n","\"\"\"\n","Created on Fri Mar  8 07:39:17 2019\n","\n","@author: james\n","\"\"\"\n","\n","import bs4\n","import requests\n","import pandas as pd\n","import numpy as np\n","from google.colab import files\n","\n","###############################################################################\n","#    Section 1 - The stem link\n","###############################################################################\n","\n","#********************************* FILL IN ************************************\n","OGA = \"https://www.ogauthority.co.uk/lessons-learned/\"\n","#******************************************************************************\n","\n","link = (OGA + \"index.html\")\n","data = requests.get(link)\n","soup = bs4.BeautifulSoup(data.content, 'html.parser')\n","\n","###############################################################################\n","#    Section 2 - Getting section URLs\n","###############################################################################\n","\n","#********************************* FILL IN ************************************\n","section = soup.find_all(\"a\")\n","#******************************************************************************\n","\n","links = []\n","\n","for item in section[1:][:6]:\n","    alpha=str(item).split(\"href=\")[1].split(\"><\")[0][1:][:-1]\n","    \n","    # Passing each section URL to bs4\n","    link = (OGA + alpha)\n","    \n","    print([link])\n","    \n","    data = requests.get(link)\n","    soup = bs4.BeautifulSoup(data.content, 'html.parser')\n","    \n","    subsec = []\n","    \n","    ###############################################################################\n","    #    Section 3 - Getting sub-section URLs\n","    ###############################################################################\n","    \n","    for word in [\"planning\",\"execution\",\"cost\"]:\n","        x=str(soup.find_all(\"div\",{\"class\":word})[0]).split(\"href=\")[1].split(\">\")[0]\n","        if \"/\" in x:\n","            x2=x.split(\"/\")[-1][:-1]\n","        else:\n","            x2=x[1:][:-1]\n","    \n","        subsec.append(x2) \n","    \n","    print(subsec)\n","    \n","    ###############################################################################\n","    #    Section 4 - Getting sub-sub-section URLs\n","    ###############################################################################\n","    \n","    k=0\n","    for word in [\"planning\",\"execution\",\"cost\"]:\n","        link = OGA+link.split(\"/\")[-3]+\"/\"+word+\"/\"+subsec[k]\n","        \n","        data = requests.get(link)\n","        soup = bs4.BeautifulSoup(data.content, 'html.parser')\n","        \n","        #********************************* FILL IN ************************************\n","        # Getting the sub-sub-sections\n","        subsubsections = soup.find_all(\"a\")\n","        #******************************************************************************\n","        \n","        k+=1\n","            \n","        for item in subsubsections:\n","            # Split on \"href\" and \"><\"\n","            beta=str(item).split(\"href=\")[1].split(\"><\")[0]\n","            # filtering out links we don't want\n","            if \"..\" not in beta and \">\" not in beta:\n","                url = str('/'.join(str(link).split(\"/\")[:-1])+'/'+beta[1:-1])\n","                links.append(url)\n","                \n","                print(url)  \n","\n","###############################################################################\n","#    Section 5 - Creating a unique list of all the urls\n","###############################################################################\n","         \n","#Prints the numer of unique links\n","links = list(dict.fromkeys(links))\n","print(len(links))\n","\n","all_text = []\n","sections = []\n","subsections = []\n","subsubsections = []\n","\n","for x in range(len(links)):\n","    link = links[x]\n","    data = requests.get(link)\n","    soup = bs4.BeautifulSoup(data.content, 'html.parser')\n","    a = len(str(soup.find_all(\"p\")).split(\"</p>\"))-1\n","    \n","    ###############################################################################\n","    #   Section 6 - Getting the sub-sub-sub-section text. But not the bullet points\n","    ###############################################################################\n","    \n","    for i in range(0,a):\n","        text = str(soup.find_all(\"p\")[i]).split(\">\")[2].split(\"<\")[0]\n","        all_text.append(text)\n","        section = ' '.join(word for word in str(link).split(\"/\")[-1].split(\"-\")[:-1])\n","        sections.append(section)\n","        subsection = str(link).split(\"/\")[-2]\n","        subsections.append(subsection)\n","        subsubsection = str(link).split(\"-\")[-1].split(\".\")[0]\n","        subsubsections.append(subsubsection)\n","\n","###############################################################################\n","#    Section 7 - Creating a data frame from all our informationn\n","###############################################################################            \n","            \n","# Creating a dataframe of the scraped text\n","df = pd.DataFrame({'Section':np.array(sections),\n","                   'Subsection':np.array(subsections),\n","                   'Sub-Subsection':np.array(subsubsections),\n","                   'Text':np.array(all_text)})\n","\n","###############################################################################\n","#    Section 8 - Remapping the shorthand words\n","###############################################################################     \n","    \n","# Remapping the 'subsection' collumn\n","def remap(x):\n","    if x == 'pm':\n","        return 'Project Management'\n","    if x == 'froc':\n","        return 'Facilities Running/ Owner Costs'\n","    if x == 'wa':\n","        return 'Well Abandonment'\n","    if x == 'fpms':\n","        return 'Facilities/ Pipeline Making Safe'\n","    if x == 'si':\n","        return 'Subsea Infrastructure'\n","    if x == 'tp':\n","        return 'Topsides Preparation'\n","    if x == 'tr':\n","        return 'Topsides Removal'\n","    if x == 'sr':\n","        return 'Substructure Removal'\n","    if x == 'tsor':\n","        return 'Topside & Substructure Onshore Recycling'\n","    if x == 'srn':\n","        return 'Site Remediation'\n","    if x == 'm':\n","        return 'Monitoring'\n","    else:\n","        return 'na'\n","    \n","\n"," \n","df['Sub-Subsection'] = df['Sub-Subsection'].apply(remap)\n","\n","###############################################################################\n","#    Section 9 - Creating our CSV file and downloading it\n","###############################################################################  \n","\n","\n","#********************************* FILL IN ************************************\n","df.to_csv(\"OGA_lessons_learned.csv\")\n","files.download(\"OGA_lessons_learned.csv\")\n","#******************************************************************************"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['https://www.ogauthority.co.uk/lessons-learned/1/planning/operating-pm.html']\n","['operating-pm.html', 'operating-wa.html', 'operating-pm.html']\n","https://www.ogauthority.co.uk/lessons-learned/1/planning/operating-pm.html\n","https://www.ogauthority.co.uk/lessons-learned/1/planning/operating-froc.html\n","https://www.ogauthority.co.uk/lessons-learned/1/planning/operating-wa.html\n","https://www.ogauthority.co.uk/lessons-learned/1/planning/operating-fpms.html\n","https://www.ogauthority.co.uk/lessons-learned/1/planning/operating-tr.html\n","https://www.ogauthority.co.uk/lessons-learned/1/planning/operating-sr.html\n","https://www.ogauthority.co.uk/lessons-learned/1/planning/operating-tsor.html\n","https://www.ogauthority.co.uk/lessons-learned/1/planning/operating-srn.html\n","https://www.ogauthority.co.uk/lessons-learned/1/planning/operating-m.html\n","https://www.ogauthority.co.uk/lessons-learned/1/execution/operating-wa.html\n","https://www.ogauthority.co.uk/lessons-learned/1/execution/operating-fpms.html\n","https://www.ogauthority.co.uk/lessons-learned/1/execution/operating-si.html\n","https://www.ogauthority.co.uk/lessons-learned/1/execution/operating-tp.html\n","https://www.ogauthority.co.uk/lessons-learned/1/execution/operating-tr.html\n","https://www.ogauthority.co.uk/lessons-learned/1/execution/operating-tsor.html\n","https://www.ogauthority.co.uk/lessons-learned/1/execution/operating-srn.html\n","https://www.ogauthority.co.uk/lessons-learned/1/cost/operating-pm.html\n","https://www.ogauthority.co.uk/lessons-learned/1/cost/operating-froc.html\n","https://www.ogauthority.co.uk/lessons-learned/1/cost/operating-wa.html\n","https://www.ogauthority.co.uk/lessons-learned/1/cost/operating-tr.html\n","https://www.ogauthority.co.uk/lessons-learned/1/cost/operating-tsor.html\n","['https://www.ogauthority.co.uk/lessons-learned/2/planning/warm-phase-wa.html']\n"],"name":"stdout"}]}]}